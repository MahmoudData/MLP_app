import streamlit as st

st.title("üìö Veille Technique")

with st.expander("üîç Qu'est-ce qu'un Perceptron Multicouche (PMC) ?"):
    st.markdown("""
Le **Perceptron Multicouche (PMC)** est un r√©seau neuronal √† **propagation avant** compos√© de :
- üü¢ Une couche d'entr√©e
- üü° Une ou plusieurs couches cach√©es
- üî¥ Une couche de sortie

Chaque couche contient un nombre variable de **neurones** qui transforment les donn√©es d'entr√©e jusqu'√† produire une sortie (classification ou r√©gression).
""")

with st.expander("üß† Architecture PMC selon la t√¢che"):
    st.markdown("""
Selon la t√¢che, l'**architecture change** :
- üî∑ **R√©gression** : activation lin√©aire en sortie
- üî∂ **Classification binaire** : activation sigmo√Øde
- üåà **Classification multiclasse** : activation softmax
""")

with st.expander("üìò D√©finitions cl√©s du Deep Learning"):
    st.markdown("""
- **Fonction d‚Äôactivation** : transforme les signaux des neurones (ReLU, Sigmoid, Tanh, Softmax)
- **Propagation** : passage des donn√©es de la couche d'entr√©e √† la sortie
- **R√©tropropagation** : calcul de l‚Äôerreur + mise √† jour des poids via le gradient
- **Loss Function** : mesure l'√©cart entre la pr√©diction et la v√©rit√©
- **Descente de gradient** : m√©thode d‚Äôoptimisation pour r√©duire l‚Äôerreur
- **Vanishing Gradients** : probl√®me o√π les gradients deviennent trop petits (ReLU > Sigmoid)
""")

with st.expander("‚öôÔ∏è Hyperparam√®tres importants d‚Äôun MLP"):
    st.markdown("""
1. **Batch size** : 32-64 recommand√© pour bonne g√©n√©ralisation  
2. **Fonction d‚Äôactivation** : ReLU (couches cach√©es), Sigmoid / Softmax (sortie)  
3. **Poids initiaux** : He pour ReLU, Xavier pour sigmoid  
4. **Dropout** : 0.2 √† 0.5 pour √©viter le sur-apprentissage  
5. **Nombre de couches cach√©es** : 2-3 pour d√©buter, plus pour mod√®les profonds  
6. **Learning rate** : 0.001 (Adam) ou 0.01 (SGD)
7. **Optimiseur** : Adam (robuste), SGD+momentum (plus fin)
""")